{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IT21174230/ML-Journey/blob/main/document_filtering_(doc2vec).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f954d992",
      "metadata": {
        "id": "f954d992",
        "outputId": "3426b87d-a529-4290-9932-e40ba05792f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coding programming languages software development web development mobile app development algorithms data structures version control devops software architecture front-end development back-end development full-stack development software testing debugging agile development object-oriented programming scripting languages database management software frameworks artificial intelligence machine learning cybersecurity cloud computing internet of things (iot) software as a service (saas) open-source software code quality code optimization software maintenance software engineering best practices continuous integration software development tools mobile app frameworks game development software development trends software engineering ethics software project management software design patterns code documentation software patents user experience design (ux) software development communities software development conferences tech startups software industry coding bootcamps it certifications code review software engineering blogs \n"
          ]
        }
      ],
      "source": [
        "collection=['software engineering.txt','data science.txt', 'travel.txt', 'music.txt', 'food.txt', 'literature.txt']\n",
        "\n",
        "corpus=[]\n",
        "\n",
        "for i,doc in enumerate(collection):\n",
        "    with open(doc) as f:\n",
        "        corpus.extend([f.read().lower().replace('\\n', ' ')])\n",
        "\n",
        "print(corpus[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c46181f",
      "metadata": {
        "id": "1c46181f"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(doc), tags=[str(i)]) for i, doc in enumerate(corpus)]\n",
        "\n",
        "model = Doc2Vec(vector_size=100, window=5, min_count=1, dm=0)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=20)\n",
        "\n",
        "model.save(\"keyword_model.mode\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "110477d7",
      "metadata": {
        "id": "110477d7",
        "outputId": "9c020dae-fc7f-4ddb-918f-3e30b8d7fbc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "# document_vector = model.dv[0]\n",
        "# print(document_vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675ef6e7",
      "metadata": {
        "id": "675ef6e7",
        "outputId": "b8db7e13-70bd-40ce-d230-3501fddf5b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input your document:cheese cake recipe for software engineers to enjoy with their coffe\n"
          ]
        }
      ],
      "source": [
        "doc_in=input('Input your document:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482e9577",
      "metadata": {
        "id": "482e9577",
        "outputId": "410c9eff-dbe1-4141-f40c-495d3b51759d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9947629, 0.99313337, 0.9934107, 0.9939112, 0.99481636, 0.9937992]\n",
            "This belongs to : ['food']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "new_doc_vec=model.infer_vector(word_tokenize(doc_in.lower()))\n",
        "\n",
        "cosine_similarities = []\n",
        "for i in range(len(collection)):\n",
        "    doc_vector = model.dv[i]\n",
        "    cos_sim = cosine_similarity([new_doc_vec], [doc_vector])\n",
        "    cosine_similarities.append(cos_sim[0][0])\n",
        "\n",
        "print(cosine_similarities)\n",
        "\n",
        "max_val = max(cosine_similarities)\n",
        "indices = [i for i, value in enumerate(cosine_similarities) if value == max_val]\n",
        "\n",
        "categories = [collection[j] for j in indices]\n",
        "\n",
        "print(f\"This belongs to : {[str(i).split('.')[0] for i in categories]}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}